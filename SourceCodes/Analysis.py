##################################################
# Visual Analysis
# Part of the Library: Sequential Regression Extrapolation
# Julie Butler Hartley
# Version 0.0.1
# Date Created: February 20, 2021
# Last Modified: March 23, 2023
#
# A collection of methods to graph data generated by the Sequentual Regression
# Extrapolation library
##################################################

##################################################
# OUTLINE
##################################################
# graph_model_outputs: Plots a known data set and a predicted data set on the same plot for comparison.
# graph_model_output_with_uncertainities: Plots a known data set and a predicted data set on the same plot for comparison.
#   Also includes the uncertainities on the prediction as a shaded region.
# graph_model_outputs_many: Plots a series of known data sets and their predictions.  Each data set will have its own
#   unique color and label.
# graph_model_outputs_with_uncertainities_many: Plots a series of known data sets and their predictions.  The uncertianity of the predictions is 
#   plotted as a shaded region with its color matching the data set. Each data set will have its own
#   unique color and label.
# visualize_difference: Plots the difference between the true data set and the predicted
#   (model) data set.
# r2_plot: Plots the known data set on the x axis and the predicted data set
#   on the y axis.  Adds labels for the R2 score and slope of the 
#   graph. Ideally, for a perfect model (i.e. the true data set and
#   the predicted data set are exactly the same), both R2 and the 
#   slope will be one
##############################
# IMPORTS
##############################
# THIRD-PARTY IMPORTS
import numpy as np 
import matplotlib.pyplot as plt
from Regression import *
from sklearn.metrics import r2_score
import matplotlib.patches as mpatches

class VisualAnalysis():
    """
    A collection of functions used to plot and analyze the results from performing an 
    extrapolation using the SRE library.
    """
    # No initilizer, just use the default
    
    ##############################
    ##    GRAPH MODEL OUTPUTS   ##
    ##############################
    def graph_model_outputs (self, joint_x_data, true_data, pred_data, x_label, 
        y_label, savename, color="black", isDisplay=True):
        """
            Inputs:
                joint_x_data (a 1D list or NumPy array of numbers): the data to be 
                    plotted on the x axis.  Must be the same of all of the ouputs 
                    given in y_data.
                true_data (a 1D list or NumPy array): the fully calculated values
                pred_data (a 1D list or NumPy array): the ML predictions of the true data
                x_label (a string): the label for the x axis
                y_label (a string): the label for the y axis
                color (a string): the color to make the plot.  Default value is black.
                savename (a string): the file name to save the finished graph to
                color (a string): the color to plot the data with
                isDisplay (a boolean): True case displays the finished graph
            Returns:
                None.
            Plots a known data set and a predicted data set on the same plot for comparison.
        """
        # Make sure the x data is not empty
        assert len(joint_x_data) != 0
        # Make sure the x alvel, the y label, and the file name are all strings
        assert isinstance(x_label, str)
        assert isinstance(y_label, str)
        assert isinstance(savename, str)
        assert isinstance(color, str)
        # Make sure the isDisplay variable is a boolean
        assert isinstance(isDisplay, bool)
        # Loop through every data set in y_data
        plt.plot(joint_x_data, true_data, label="Calculated", color=color, 
            linewidth=2)
        plt.scatter(joint_x_data, pred_data, label="Predicted", color=color, 
            s=75, marker="^")
        # Add the x and y labels to the graph.  Also include a legend.
        plt.xlabel(x_label,fontsize=14)
        plt.ylabel(y_label,fontsize=14)
        plt.legend(fontsize=14)
        # Save the completed graph and if needed display it
        plt.savefig(savename,dpi=1000,bbox_inches='tight')
        if isDisplay:
            plt.show()
    
    ##############################################
    ## GRAPH MODEL OUTPUTS WITH UNCERTAINITIES  ##
    ##############################################
    def graph_model_output_with_uncertainities (self,joint_x_data, true_data, pred_data, 
        uncertainities,  x_label, y_label,savename, color="black", isDisplay=True):
        """
            Inputs:
                joint_x_data (a 1D list or NumPy array of numbers): the data to be 
                    plotted on the x axis.  Must be the same of all of the ouputs 
                    given in y_data.
                true_data (a 1D list or NumPy array): the fully calculated values
                pred_data (a 1D list or NumPy array): the ML predictions of the true data
                uncertainities (a 1D list of NumPy array): the standard deviation on each point
                    in pred_data. 
                x_label (a string): the label for the x axis
                y_label (a string): the label for the y axis
                color (a string): the color to make the plot.  Default value is black.
                savename (a string): the file name to save the finished graph to
                color (a string): the color to plot the data with                
                isDisplay (a boolean): True case displays the finished graph
            Returns:
                None.
            Plots a known data set and a predicted data set on the same plot for comparison.
            Also includes the uncertainities on the prediction as a shaded region.
        """        
        # Make sure the x data is not empty
        assert len(joint_x_data) != 0
        # Make sure the x alvel, the y label, and the file name are all strings
        assert isinstance(x_label, str)
        assert isinstance(y_label, str)
        assert isinstance(savename, str)
        # Make sure the isDisplay variable is a boolean
        assert isinstance(isDisplay, bool)
        # Loop through every data set in y_data
        plt.plot(joint_x_data, true_data, label="Calculated", color=color, linewidth=2)
        plt.scatter(joint_x_data, pred_data, label="Predicted", color=color, s=75, marker="^")
        plt.fill_between(joint_x_data.ravel(), pred_data - uncertainities, pred_data + uncertainities, 
            color=color, alpha=0.2, label="Uncertainity on Pred.")
        # Add the x and y labels to the graph.  Also include a legend.
        plt.xlabel(x_label,fontsize=14)
        plt.ylabel(y_label,fontsize=14)
        plt.legend(fontsize=14)
        # Save the completed graph and if needed display it
        plt.savefig(savename,dpi=1000,bbox_inches='tight')
        if isDisplay:
            plt.show()

    ##############################
    ## GRAPH MODEL OUTPUTS MANY ##
    ##############################
    def graph_model_outputs_many (self, joint_x_data, true_data, pred_data, x_label, y_label, colors, labels,
        savename, isDisplay=True):
        """
            Inputs:
                joint_x_data (a 1D list or NumPy array of numbers): the data to be 
                    plotted on the x axis.  Must be the same of all of the ouputs 
                    given in y_data.
                true_data (a 2D list or NumPy array): the fully calculated values
                pred_data (a 2D list or NumPy array): the ML predictions of the true data
                x_label (a string): the label for the x axis
                y_label (a string): the label for the y axis
                color (a string): the colors to plot the data sets.  Should have one color per data set
                labels (a 1D list or NumPy array): a list of labels to apply to the data.  Should have 
                    one label per data set.
                savename (a string): the file name to save the finished graph to
                color (a string): the color to plot the data with                
                isDisplay (a boolean): True case displays the finished graph
            Returns:
                None.
            Plots a series of known data sets and their predictions.  Each data set will have its own
            unique color and label.
        """  
        fig, ax = plt.subplots(1, 1)
        assert len(true_data) == len(pred_data)
        assert len(true_data) == len(colors)
        assert len(true_data) == len(labels)
        # Make sure the x data is not empty
        assert len(joint_x_data) != 0
        # Make sure the x alvel, the y label, and the file name are all strings
        assert isinstance(x_label, str)
        assert isinstance(y_label, str)
        assert isinstance(savename, str)
        # Make sure the isDisplay variable is a boolean
        assert isinstance(isDisplay, bool)
        # Loop through every data set in y_data
        ax.plot(joint_x_data, true_data[0], label="Calculated", color=colors[0], linewidth=2)
        ax.scatter(joint_x_data, pred_data[0], label="Predicted", color=colors[0], s=75, marker="^")
        for i in range(1, len(true_data)):
            ax.plot(joint_x_data, true_data[i],  color=colors[i], linewidth=2)
            ax.scatter(joint_x_data, pred_data[i],  color=colors[i], s=75, marker="^")
        
        patches = []
        for i in range(len(colors)):
            patch = mpatches.Patch(color=colors[i], label=labels[i])
            patches.append(patch)
        leg_patches = plt.legend(handles=patches,fontsize=14,loc=(1.025,0.35))
        plt.gca().add_artist(leg_patches)            
        # Add the x and y labels to the graph.  Also include a legend.
        plt.xlabel(x_label,fontsize=14)
        plt.ylabel(y_label,fontsize=14)
        plt.legend(loc=(1.025,0.05),fontsize=14)
        # Save the completed graph and if needed display it
        plt.savefig(savename,dpi=1000,bbox_inches='tight')
        if isDisplay:
            plt.show()
       
    ##################################################
    ## GRAPH MODEL OUTPUTS WITH UNCERTAINITIES MANY ##
    ##################################################
    def graph_model_outputs_with_uncertainities_many (self, joint_x_data, true_data, 
        pred_data, uncertainities, x_label, y_label, colors, labels,savename, isDisplay=True):
        """
            Inputs:
                joint_x_data (a 1D list or NumPy array of numbers): the data to be 
                    plotted on the x axis.  Must be the same of all of the ouputs 
                    given in y_data.
                true_data (a 2D list or NumPy array): the fully calculated values
                pred_data (a 2D list or NumPy array): the ML predictions of the true data
                uncertainities (a 2D list of NumPy array): the standard deviation on each point
                    in pred_data. 
                x_label (a string): the label for the x axis
                y_label (a string): the label for the y axis
                color (a string): the colors to plot the data sets.  Should have one color per data set
                labels (a 1D list or NumPy array): a list of labels to apply to the data.  Should have 
                    one label per data set.
                savename (a string): the file name to save the finished graph to
                color (a string): the color to plot the data with                
                isDisplay (a boolean): True case displays the finished graph
            Returns:
                None.
            Plots a series of known data sets and their predictions.  The uncertianity of the predictions is 
            plotted as a shaded region with its color matching the data set. Each data set will have its own
            unique color and label.
        """             
        fig, ax = plt.subplots(1, 1)
        assert len(true_data) == len(pred_data)
        assert len(true_data) == len(colors)
        assert len(true_data) == len(labels)
        # Make sure the x data is not empty
        assert len(joint_x_data) != 0
        # Make sure the x alvel, the y label, and the file name are all strings
        assert isinstance(x_label, str)
        assert isinstance(y_label, str)
        assert isinstance(savename, str)
        # Make sure the isDisplay variable is a boolean
        assert isinstance(isDisplay, bool)
        # Loop through every data set in y_data
        ax.plot(joint_x_data, true_data[0], label="Calculated", color=colors[0], linewidth=2)
        ax.scatter(joint_x_data, pred_data[0], label="Predicted", color=colors[0], s=75, marker="^")
        ax.fill_between(joint_x_data.ravel(), pred_data[0] - uncertainities[0], pred_data[0] + uncertainities[0], 
            color=colors[0], alpha=0.2, label="Uncertainity on Pred.")
        for i in range(1, len(true_data)):
            ax.plot(joint_x_data, true_data[i],  color=colors[i], linewidth=2)
            ax.scatter(joint_x_data, pred_data[i],  color=colors[i], s=75, marker="^")
            ax.fill_between(joint_x_data.ravel(), pred_data[i] - uncertainities[i], pred_data[i] + uncertainities[i], 
                color=colors[i], alpha=0.2)
        
        patches = []
        for i in range(len(colors)):
            patch = mpatches.Patch(color=colors[i], label=labels[i])
            patches.append(patch)
        leg_patches = plt.legend(handles=patches,fontsize=14,loc=(1.025,0.3))
        plt.gca().add_artist(leg_patches)            
        # Add the x and y labels to the graph.  Also include a legend.
        plt.xlabel(x_label,fontsize=14)
        plt.ylabel(y_label,fontsize=14)
        plt.legend(loc=(1.025,0.-.1),fontsize=14)
        # Save the completed graph and if needed display it
        plt.savefig(savename,dpi=1000,bbox_inches='tight')
        if isDisplay:
            plt.show()            
            
            
    ##############################
    ##   VISUALIZE DIFFERENCE   ##
    ##############################
    def visualize_difference (self, x_data, true_data, model_data, x_label, y_label,savename, isDisplay=True):
        """
            Inputs:
                x_data  (a list): the x component of the data set
                true_data (a list): the known data set
                model_data (a list): the data set predicted by a regression 
                    algorithm
                x_label (a string): the label for the x axis
                y_label (a string): the label for the y axis
                savename (a string): the name for the completed graph to be
                    saved as.
                isDisplay (a boolean): True case displays the completed graph
                    to the screen.  Default value is true               
            Returns:
                None.
            Plots the difference between the true data set and the predicted
            (model) data set.
        """
        # Check the inputs
        assert len(true_data) == len(model_data)
        assert len(x_data) == len(model_data)
        assert isinstance(x_label, str)
        assert isinstance(y_label, str)
        assert isinstance(savename, str)
        assert isinstance(isDisplay, bool)
        # Find the difference and then plot it
        difference = np.asarray(true_data) - np.asarray(model_data)
        plt.scatter (x_data, difference)
        # Add x and y labels, save the completed graph and display if needed
        plt.xlabel(x_label)
        plt.ylabel(y_label)
        plt.savefig(savename,dpi=1000,bbox_inches='tight')
        if isDisplay:
            plt.show()

    ##############################
    ##          R2 PLOT         ##
    ##############################
    def R2_plot (self, true_data, predicted_data, savename, isDisplay=True):
        """
            Inputs:
                true_data (a list or NumPy array): the known data set
                predicted_data (a list or NumPy array): the predicted data set
                    from a Regression algorithm
                savename (a string): the name for the completed graph to be
                    saved as.
                isDisplay (a boolean): True case displays the completed graph
                    to the screen.  Default value is true                               
            Returns:
                None.
            Plots the known data set on the x axis and the predicted data set
            on the y axis.  Adds labels for the R2 score and slope of the 
            graph. Ideally, for a perfect model (i.e. the true data set and
            the predicted data set are exactly the same), both R2 and the 
            slope will be one.
        """
        # Check the inputs
        assert len(true_data) == len(predicted_data)
        assert isinstance(savename, str)
        assert isinstance(isDisplay, bool) 
        # Create a scatter plot of the true and predicted data sets 
        plt.scatter(true_data, predicted_data)
        # Get the R2 score and add it to the plot in the top left corner
        r2 = r2_score(true_data, predicted_data)
        corner1 = np.min(true_data)
        corner2 = np.max(predicted_data)
        plt.annotate("R2 Score: {:.3f}".format(r2), (corner1, corner2), fontsize=16)
        # Get the slope between the two data sets and add it to the plot in
        # the bottom right corner
        lir = LiR(False)
        lir.fit(true_data, predicted_data)
        slope = lir.get_parameters()[0]
        corner3 = np.max(true_data)
        corner4 = np.min(predicted_data)
        plt.annotate("Slope: {:.3f}".format(slope), (corner3, corner4), fontsize=16)
        # Add x and y labels, save the completed graph and display if needed        
        plt.xlabel("True Data")
        plt.ylabel("Predicted Data")
        plt.savefig(savename)
        if isDisplay:
            plt.show()      


##################################################
# Error Analysis
# Part of the Library: Sequential Regression Extrapolation
# Julie Butler Hartley
# Version 0.0.1
# Date Created: February 20, 2021
# Last Modified: March 14, 2023
#
# A collection of methods to graph data generated by the Sequentual Regression
# Extrapolation library
##################################################

##################################################
# OUTLINE
##################################################
# mse: Finds the mean-squared error of the two data sets given as inputs.
# r2: Calculates and returns the R2 score between a known data set and
#   the data set as predicted by a regression algorithm.
# alpha_tune: Tunes a ridge regression model to find the optimal value of alpha
#   from a given range.  Works with regular ridge regression or with
#   sequential extrapolation format
# krr_parameter_tune: to be implemented later
# rmse: Computes the RMSE score between two data sets.
# percent_error: Computes the percent error between two data sets.

class ErrorAnalysis():
    """
        A collection of methods for analyzing the performance of a regression
        algorithm.
    """

    ##############################
    ## MSE (Mean-Squared Error) ##
    ##############################
    def mse (self, A, B):
        """
            Inputs:
                A, B (lists of the same length): two different data sets
            Returns:
                Unnamed (a float): the mean-squared error score between data sets A and B
            Finds the mean-squared error of the two data sets given as inputs.
        """
        A = np.asarray(A)
        B = np.asarray(B)
        return ((A-B)**2).mean()

    ##############################
    ##            R2            ##
    ##############################
    def r2 (self, true_data, predicted_data):
        """
            Inputs:
                true_data, predicted_data (lists): the known and predicted
                    data sets
            Returns:
                Unnamed (a float): the R2 score between the two data sets
            Calculates and returns the R2 score between a known data set and
            the data set as predicted by a regression algorithm.  For a
            perfect model the R2 score should be 1.
        """
        return r2_score(true_data, predicted_data)

    ##############################
    ##          ALPHA TUNE      ##
    ##############################
    def alpha_tune (self, X_train, y_train, X_test, y_test, test_alpha_values, 
        isExtrapolate = True, isModified = True, isGraph = False, x_label = '', 
        y_label = '', savename = '', seq=2):
        """
            Inputs:
                X_train, y_train (lists): the training data
                X_test, y_test (lists): the test data set
                test_alpha_values (a list): the alpha value to be tested to
                    find the best one 
                isExtrapolate (a boolean): True case means extrapolation will 
                    be used for prediction, False means the regular prediction
                    method will be used.  Default value is True.
                isModified (a boolean): True means that ridge regression will 
                    normalize the data and set an intercept.  Default case is
                    True
                isGraph (a boolean): True case means the resulting models will
                    be graphed for each tested alpha.  Default value is False.
                x_label (a string): the label for the x axis.  Default value
                    is an empty string.
                y_label (a string): the label for the x axis.  Default value
                    is an empty string.
                savename (a string): the name to save the grapha as. Default
                    value is an empty string
                seq (an int): the length of the sequence used in extrapolation
            Returns:
                best_alpha (a float): the alpha value that give the lowest MSE
                    score
            Tunes a ridge regression model to find the optimal value of alpha
            from a given range.  Works with regular ridge regression or with
            sequential extrapolation format.

        """
        # Check the inputs
        assert len(test_alpha_values) != 0
        assert len(X_train) == len(y_train)
        assert len(X_test) == len(y_test)
        assert isinstance(isExtrapolate, bool)
        assert isinstance(isModified, bool)
        assert isinstance(isGraph, bool)
        assert isinstance(x_label, str)
        assert isinstance(y_label, str)
        assert isinstance(savename, str)
        assert isinstance(seq, int)
        # Initalize values to determine the best alpha
        best_score = 100
        best_alpha = None
        # If graphing is needed, set up the lists to store the results to be
        # graphed later
        if isGraph:
            models = [y_test]
            scores = []
        # For each value on the list of test values:
        for alpha in test_alpha_values:
            # Create a ridge regression instance
            RR = RR(alpha, isModified)
            # If extrapolation is needed, reformat the training data
            if isExtrapolate:
                X_train, y_train = format_sequential_data(y_train, seq)
            # Fit the RR algorithm and predict the test set using the 
            # method indicated in the inputs
            RR.fit(X_train, y_train)
            if isExtrapolate:
                y_pred = extrapolate(RR, y_train, len(y_test), seq)
            else:
                y_pred = RR.predict(X_test)
            # Get the MSE score and determine if it is the current lowest
            score = mse(y_test, y_pred)
            if mse < best_score:
                best_score = score
                best_alpha = alpha
            # Save the model to be graphed later if needed
            if isGraph:
                models.append(y_pred)
                scores.append(score)
        # Print the best value to the terminal
        print()
        print ("Best alpha value is", best_alpha, "with a model MSE of", best_score)
        print()
        # If graphing is needed:
        if isGraph:
            # Set up the labels, the first is the true data and then one for
            # each of the alpha values, then graph the corresponding data set
            labels = ["True Data"]
            for i in range(len(scores)):
                labels.append("Alpha:" + str(test_alpha_values[i]) + ", Score:" +\
                    str(scores[i]))
            va = VisualAnalysis()
            va.graph_model_outputs (X_test, models, labels, x_label, y_train, 
                savename, isDisplay=True)   
        return best_alpha               

    ##############################
    ##    KRR PARAMETER TUNE    ##
    ##############################
    def krr_parameter_tune (self):
        print("TO BE IMPLEMENTED LATER")
        
    ####################################
    ## RMSE (Root Mean Squared Error) ##
    ####################################  
    def rmse(self, A,B):
        """
            Inputs:
                A,B (lists or NumPy arrays): the data.  A and B must be the same
                    length.
            Returns:
                Unnamed (a float): the RMSE score between A and B
            Computes the RMSE score between two data sets.
        """
        assert len(A)==len(B)
        return np.sqrt(np.average((np.asarray(A)-np.asarray(B))**2))

    ##############################
    ##       PERCENT ERROR      ##
    ############################## 
    def percent_error (self, prediction, truth):
        """
            Inputs:
                prediction (a float, list, or Numpy array): the predicted value(s)
                truth (a float, list, or NumPy array): the true value(s)
            Returns:
                Unnamed (a float): the percent error between the two inputs
            Computes the percent error between the given prediction and true values
        """
        prediction = np.asarray(prediction)
        truth = np.asarray(truth)
        return np.average(np.abs((prediction-truth)/truth))*100
            
